# Analysing comments to understand their sentiment and polarity towards the company

# importing all required libraries
import os
import time
import json
import csv
import pandas as pd
from openai import OpenAI
from secret_pass import secret_key  # getting secret key for ChatGPT API

commentsData = []  # empty list to store comment's polarity

# reading all the comments and data in the output.json file
with open('output.json', 'r') as file:
    comments = json.load(file)

# iterating through each comment in the comments from the output.json file
for comment in comments:
    data = {}  # empty data dictionary to add comments meta data to create a query for the gpt api

    print('\n\n\n')

    comment_text = comment.get("comment", "Unkown user")  # get comment data from comment
    title = comment.get("titles", "Unkown title")  # get title data from comment

    # print(comment_text)
    # print(title)

    # adding metadata to the data dictionary
    data["comment"] = comment_text  # comment body
    data["title"] = title  # comment title
    data["company"] = "BudLight"  # company targeted
    data["question"] = "Rate the comment on a positivity scale between -100 (negative) to 100 (positive) for the company. Respond with numbers only. Do not include any explaination or text."  # question for the AI agent

    # print(data)

    # adding the data dictionary to the commentsData list
    commentsData.append(data)

# creating a blank CSV file to append comment analysis to
with open('analysisList.csv', 'w') as f:
    pass


# function to add polarity score to analysisList.csv file
def write_num_to_csv(number, filename='analysisList.csv'):
    with open(filename, mode='a', newline='', encoding='utf-8') as file:
        writer = csv.writer(file)
        writer.writerow([number])


# empty list to store polarity measurements of all the comments analyzed
polarity = []

flag = 0  # counter variable to keep track of number of API calls made
# parsing all the comments into the ChatGPT API
for comment in commentsData:
    client = OpenAI(api_key=secret_key)  # initializing the GPT API with the api key

    # engineering the API input token posts
    response = client.responses.create(
        model="gpt-4.1-nano",
        input=[
            {
                'role': 'user',
                'content': json.dumps(comment)
            }
        ]
    )

    analysis = response.output_text  # getting an analysis from the API response in a string
    polarity.append(analysis)  # adding the polarity score generated by the API to polarity list
    write_num_to_csv(analysis)  # adding the polarity score generated by the API to the analysisList.csv file

    print(f'{comment.get("comment")}: {analysis}')

    flag += 1  # moving the counter forward

    # checking for the flag counter having reached over 220 iterations
    if flag > 220:
        print("\nDowntime for 60 seconds...")
        time.sleep(55)  # sleeping the program to give the API server some breathing time
        flag = 0  # resetting the flag counter
        print("Work resumed \n\n")

# adding the comment polarity generated to the comments dataset under a new field "polarity"
for i in range(len(polarity)):
    comments[i]['polarity'] = polarity[i]

# adding the new comments dataset to the output.json file
with open('output.json', 'w') as file:
    json.dump(comments, file, indent=4)

# converting the json data to a pandas Data Frame
df = pd.DataFrame(comments)
df.to_csv('analysis_output.csv', index=False, encoding='utf-8')  # exporting the Data Frame to a CSv file
print("successfully converted .JSON file to .CSV file with comment polarity measurements")

